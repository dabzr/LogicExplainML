{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from anchor import utils\n",
    "from anchor import anchor_tabular\n",
    "import re\n",
    "import sklearn\n",
    "from sklearn.datasets import load_iris, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from pmlb import fetch_data\n",
    "from z3 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_constraints_expression(X, round = 0):\n",
    "    constraints = []\n",
    "\n",
    "    for i in range(X.shape[1]):\n",
    "        feature_values = X[:, i] * 10**round\n",
    "        # np.unique\n",
    "        min_val, max_val = feature_values.min(), feature_values.max()\n",
    "\n",
    "        x = Real(f\"x{i}\")\n",
    "        min = RealVal(min_val)\n",
    "        max = RealVal(max_val)\n",
    "\n",
    "        constraint = And(min <= x, x <= max)\n",
    "        constraints.append(constraint)\n",
    "\n",
    "    return And(*constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_paths_expression(tree, tree_index, class_index, round = 0):\n",
    "    tree_ = tree.tree_\n",
    "    feature = tree_.feature\n",
    "    threshold = tree_.threshold\n",
    "    value = tree_.value\n",
    "\n",
    "    paths = []\n",
    "    o = Real(f\"o_{tree_index}_{class_index}\")\n",
    "\n",
    "    def traverse(node, path_conditions):\n",
    "\n",
    "        if feature[node] == -2:\n",
    "            leaf_value = value[node][0][0]\n",
    "            path_formula = And(path_conditions)\n",
    "            implication = Implies(path_formula, o == leaf_value)\n",
    "            paths.append(implication)\n",
    "        else:\n",
    "\n",
    "            x = Real(f\"x{feature[node]}\")\n",
    "            left_condition = x <= threshold[node]\n",
    "            right_condition = x > threshold[node]\n",
    "            traverse(tree_.children_left[node], path_conditions + [left_condition])\n",
    "            traverse(tree_.children_right[node], path_conditions + [right_condition])\n",
    "\n",
    "    traverse(0, [])\n",
    "    return And(*paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_trees_expression(model):\n",
    "    formulas = []\n",
    "    for i, estimators in enumerate(model.estimators_):\n",
    "        for class_index, estimator in enumerate(estimators):\n",
    "            formula = tree_paths_expression(estimator, i, class_index)\n",
    "            formulas.append(formula)\n",
    "    return And(*formulas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_function_expression(model, x):\n",
    "    learning_rate = model.learning_rate\n",
    "    estimators = model.estimators_\n",
    "    n_classes = 1 if model.n_classes_ <= 2 else model.n_classes_\n",
    "\n",
    "    decision = model.decision_function(x)\n",
    "    predicted_class = model.predict(x)[0]\n",
    "\n",
    "    estimator_results = []\n",
    "    for estimator in estimators:\n",
    "        class_predictions = [tree.predict(x) for tree in estimator]\n",
    "        estimator_results.append(class_predictions)\n",
    "\n",
    "    estimator_sum = np.sum(estimator_results, axis=0) * learning_rate\n",
    "    init_value = decision - estimator_sum.T\n",
    "\n",
    "    equation_list = []\n",
    "    for class_number in range(n_classes):\n",
    "        estimator_list = []\n",
    "        for estimator_number in range(len(estimators)):\n",
    "            o = Real(f\"o_{estimator_number}_{class_number}\")\n",
    "            estimator_list.append(o)\n",
    "        equation_o = Sum(estimator_list) * learning_rate + init_value[0][class_number]\n",
    "        equation_list.append(equation_o)\n",
    "\n",
    "    if n_classes <= 2:\n",
    "        if predicted_class == 0:\n",
    "            final_equation = equation_list[0] < 0\n",
    "        else:\n",
    "            final_equation = equation_list[0] > 0\n",
    "    else:\n",
    "        compare_equation = []\n",
    "        for class_number in range(n_classes):\n",
    "            if predicted_class != class_number:\n",
    "                compare_equation.append(\n",
    "                    equation_list[predicted_class] > equation_list[class_number]\n",
    "                )\n",
    "        final_equation = compare_equation\n",
    "\n",
    "    return And(final_equation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "anchor to expressions functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_expression(feature, operator, value):\n",
    "    z3feature = Real(feature)\n",
    "    if operator == \"<=\":\n",
    "        expression = z3feature <= float(value)\n",
    "    elif operator == \">=\":\n",
    "        expression = z3feature >= float(value)\n",
    "    elif operator == \"<\":\n",
    "        expression = z3feature < float(value)\n",
    "    elif operator == \">\":\n",
    "        expression = z3feature > float(value)\n",
    "    elif operator == \"==\" or operator == \"=\":\n",
    "        expression = z3feature == float(value)\n",
    "    return expression\n",
    "\n",
    "\n",
    "def anchor_z3_expression(exp):\n",
    "    pattern = r\"x\\d+\"\n",
    "    operator_map = {\"<\": \">\", \">\": \"<\", \"<=\": \">=\", \">=\": \"<=\", \"=\": \"=\", \"==\": \"==\"}\n",
    "\n",
    "    expressions = []\n",
    "    features = []\n",
    "    for name in exp:\n",
    "        tokens = name.split(\" \")\n",
    "        match = re.search(pattern, name)\n",
    "\n",
    "        if match:\n",
    "            feature = match.group()\n",
    "            if tokens[0] == feature:\n",
    "                operator, value = tokens[1], tokens[2]\n",
    "                expressions.append(make_expression(feature, operator, value))\n",
    "            elif tokens[2] == feature and len(tokens) < 5:\n",
    "                operator = operator_map[tokens[1]]\n",
    "                value = tokens[0]\n",
    "                expressions.append(make_expression(feature, operator, value))\n",
    "            elif len(tokens) == 5:\n",
    "                operator1 = operator_map[tokens[1]]\n",
    "                operator2 = tokens[3]\n",
    "                expressions.append(make_expression(feature, operator1, tokens[0]))\n",
    "                expressions.append(make_expression(feature, operator2, tokens[4]))\n",
    "            else:\n",
    "                print(\"expression error\")\n",
    "                continue\n",
    "            features.append(feature)\n",
    "\n",
    "    return expressions, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_when_delta_zero(self, instance, verbose=False):\n",
    "    print(\"explain_when_delta_zero:\")\n",
    "    opt = Optimize()\n",
    "\n",
    "    anchor_variables = []\n",
    "    for formula in self.anchor_expressions:\n",
    "      anchor_variables.append(str(formula.arg(0)))\n",
    "\n",
    "    feature_names = [f'x{i}' for i in range(instance.shape[0])]\n",
    "    opt.add(delta >= 0)\n",
    "    for i, var in enumerate(feature_names):\n",
    "      if var in anchor_variables:\n",
    "        z3_var = Real(var)\n",
    "        opt.add((instance[i]) - delta <= z3_var, z3_var <= (instance[i]) + delta)\n",
    "        # print(f'{instance[i]} - {delta} <= {var}, {var} <= {instance[i]} + {delta}')\n",
    "\n",
    "    # not D\n",
    "    self.D = decision_function_expression(self.model, [instance])\n",
    "\n",
    "    # model\n",
    "    opt.add(self.T)\n",
    "    opt.add(Not(self.D))\n",
    "\n",
    "    # minimize delta\n",
    "    opt.minimize(delta)\n",
    "\n",
    "    if opt.check() == sat:\n",
    "      model = opt.model()\n",
    "      delta_value = model.eval(delta).as_decimal(3)\n",
    "      delta_value = delta_value.replace('?', '')\n",
    "      print(f'delta = {delta_value}')\n",
    "\n",
    "      constraints = []\n",
    "\n",
    "      for i, var in enumerate(feature_names):\n",
    "        if var in anchor_variables:\n",
    "          z3_var = Real(var)\n",
    "          feature_expression = z3_var == (instance[i])\n",
    "          lower_bound = RealVal(instance[i] - float(delta_value))\n",
    "          upper_bound = RealVal(instance[i] + float(delta_value))\n",
    "          constraints.append(simplify(And(lower_bound <= z3_var, z3_var <= upper_bound)))\n",
    "\n",
    "      print(constraints)\n",
    "    else:\n",
    "      print(\"Problema inviável!\")\n",
    "      print(anchor_expressions)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExplainerCompleter:\n",
    "    def __init__(self, model, data, round=None):\n",
    "        self.model = model\n",
    "\n",
    "        # model T\n",
    "        self.T_constraints = feature_constraints_expression(data)\n",
    "        self.T_model = model_trees_expression(self.model)\n",
    "        self.T = And(self.T_model, self.T_constraints)\n",
    "\n",
    "    def explain_instance(self, instance, exp, verbose=False, delta_fix = True):\n",
    "        opt = Optimize()\n",
    "        self.exp = exp\n",
    "\n",
    "        # anchor expressions\n",
    "        anchor_expressions, anchor_features = anchor_z3_expression(exp.names())\n",
    "        self.anchor_expressions = anchor_expressions\n",
    "        self.anchor_features = anchor_features\n",
    "        opt.add(anchor_expressions)\n",
    "\n",
    "        # delta\n",
    "        # delta >= 0\n",
    "        # todas as features que não estao no anchor > fazer as igualdades delta\n",
    "        anchor_variables = []\n",
    "        for formula in anchor_expressions:\n",
    "            anchor_variables.append(str(formula.arg(0)))\n",
    "\n",
    "        feature_names = [f\"x{i}\" for i in range(instance.shape[0])]\n",
    "\n",
    "        if delta_fix == True:\n",
    "            delta = Int(\"delta\")\n",
    "        else:\n",
    "            delta = Real(\"delta\")\n",
    "        opt.add(delta >= 0)\n",
    "        for i, var in enumerate(feature_names):\n",
    "            if var not in anchor_variables:  # and importance_dic[var] != 0:\n",
    "                z3_var = Real(var)\n",
    "                opt.add(\n",
    "                    (instance[i]) - delta <= z3_var, z3_var <= (instance[i]) + delta\n",
    "                )\n",
    "                # print(f'{instance[i]} - {delta} <= {var}, {var} <= {instance[i]} + {delta}')\n",
    "\n",
    "        # not D\n",
    "        self.D = decision_function_expression(self.model, [instance])\n",
    "\n",
    "        # model\n",
    "        opt.add(self.T)\n",
    "        opt.add(Not(self.D))\n",
    "\n",
    "        # minimize delta\n",
    "        opt.minimize(delta)\n",
    "        if opt.check() == sat:\n",
    "            if verbose:\n",
    "                for var in opt.model():\n",
    "                    print(var, \"=\", opt.model()[var])\n",
    "            print(\"delta =\", opt.model().eval(delta))\n",
    "        else:\n",
    "            print(\"(unsat == correct)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_option(rational_to_decimal=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_iris = GradientBoostingClassifier(n_estimators=100, max_depth=3, random_state=101)\n",
    "\n",
    "iris = load_iris()\n",
    "X_iris, y_iris = iris.data, iris.target\n",
    "\n",
    "X_iris_train, X_iris_test, y_iris_train, y_iris_test = train_test_split(\n",
    "    X_iris, y_iris, test_size=0.2, random_state=101\n",
    ")\n",
    "\n",
    "gb_iris.fit(X_iris_train, y_iris_train)\n",
    "y_pred = gb_iris.predict(X_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta = 1\n",
      "delta = 0\n",
      "delta = 1\n",
      "delta = 0\n",
      "(unsat == correct)\n",
      "delta = 0\n",
      "delta = 0\n",
      "delta = 0\n",
      "delta = 0\n",
      "delta = 1\n",
      "delta = 1\n",
      "(unsat == correct)\n",
      "(unsat == correct)\n",
      "delta = 0\n",
      "delta = 0\n",
      "(unsat == correct)\n",
      "delta = 1\n",
      "delta = 0\n",
      "(unsat == correct)\n",
      "delta = 0\n",
      "delta = 0\n",
      "delta = 0\n",
      "(unsat == correct)\n",
      "(unsat == correct)\n",
      "delta = 0\n",
      "delta = 1\n",
      "delta = 0\n",
      "(unsat == correct)\n",
      "(unsat == correct)\n",
      "delta = 0\n",
      "(unsat == correct)\n",
      "delta = 0\n",
      "delta = 1\n",
      "delta = 1\n",
      "delta = 0\n",
      "(unsat == correct)\n",
      "delta = 0\n",
      "(unsat == correct)\n",
      "(unsat == correct)\n",
      "(unsat == correct)\n",
      "delta = 0\n",
      "delta = 1\n",
      "delta = 0\n",
      "delta = 1\n",
      "(unsat == correct)\n",
      "(unsat == correct)\n",
      "(unsat == correct)\n",
      "delta = 0\n",
      "(unsat == correct)\n",
      "(unsat == correct)\n",
      "delta = 1\n",
      "delta = 1\n",
      "(unsat == correct)\n",
      "delta = 0\n",
      "delta = 0\n",
      "delta = 0\n",
      "(unsat == correct)\n",
      "(unsat == correct)\n",
      "delta = 1\n",
      "delta = 1\n",
      "(unsat == correct)\n",
      "delta = 1\n",
      "delta = 0\n",
      "delta = 1\n",
      "(unsat == correct)\n",
      "(unsat == correct)\n",
      "delta = 0\n",
      "delta = 1\n",
      "delta = 1\n",
      "delta = 0\n",
      "delta = 0\n",
      "delta = 0\n",
      "delta = 1\n",
      "(unsat == correct)\n",
      "delta = 1\n",
      "delta = 0\n",
      "delta = 0\n",
      "delta = 1\n",
      "(unsat == correct)\n",
      "delta = 1\n",
      "(unsat == correct)\n",
      "delta = 0\n",
      "delta = 0\n",
      "(unsat == correct)\n",
      "delta = 0\n",
      "(unsat == correct)\n",
      "delta = 1\n",
      "delta = 0\n",
      "delta = 1\n",
      "(unsat == correct)\n",
      "(unsat == correct)\n",
      "delta = 1\n",
      "delta = 0\n",
      "delta = 0\n",
      "(unsat == correct)\n",
      "(unsat == correct)\n",
      "(unsat == correct)\n",
      "delta = 0\n",
      "delta = 0\n",
      "delta = 0\n",
      "(unsat == correct)\n",
      "(unsat == correct)\n",
      "delta = 1\n",
      "delta = 0\n",
      "(unsat == correct)\n",
      "delta = 1\n",
      "delta = 0\n",
      "delta = 1\n",
      "delta = 0\n",
      "delta = 1\n",
      "delta = 1\n",
      "(unsat == correct)\n",
      "delta = 1\n",
      "delta = 0\n",
      "delta = 0\n",
      "delta = 0\n",
      "delta = 0\n",
      "delta = 0\n",
      "(unsat == correct)\n",
      "delta = 0\n"
     ]
    }
   ],
   "source": [
    "explainercomp = ExplainerCompleter(gb_iris, X_iris)\n",
    "iris_features_x = [f\"x{i}\" for i in range(len(iris.feature_names))]\n",
    "\n",
    "anchor_explainer = anchor_tabular.AnchorTabularExplainer(\n",
    "    gb_iris.classes_, iris_features_x, X_iris, categorical_names={}\n",
    ")\n",
    "\n",
    "possible_lens = []\n",
    "possible_exp = []\n",
    "for i in range(len(X_iris_train)):\n",
    "    exp = anchor_explainer.explain_instance(\n",
    "        X_iris_train[i], gb_iris.predict, threshold=0.95\n",
    "    )\n",
    "    explainercomp.explain_instance(X_iris_train[i], exp)\n",
    "    # if len(exp.names()) not in possible_lens:\n",
    "    #   print((exp.names()))\n",
    "    #   print(anchor_z3_expression(exp.names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_iris = GradientBoostingClassifier(n_estimators=100, max_depth=3, random_state=101)\n",
    "\n",
    "iris = load_iris()\n",
    "X_iris, y_iris = iris.data, iris.target\n",
    "\n",
    "X_iris_train, X_iris_test, y_iris_train, y_iris_test = train_test_split(\n",
    "    X_iris, y_iris, test_size=0.2, random_state=101\n",
    ")\n",
    "\n",
    "gb_iris.fit(X_iris_train, y_iris_train)\n",
    "y_pred = gb_iris.predict(X_iris)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
