{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from z3 import *\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from z3 import *\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class XGBoostExplainer:\n",
    "    \"\"\"Apenas classificação binária e base_score = None\n",
    "    data = X. labels = y\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, data):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            model (XGBoost): xgboost model fited\n",
    "            data (DataFrame): dataframe (X or X_train)\n",
    "            labels (array): y (targets)\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.data = data.values\n",
    "        self.columns = data.columns\n",
    "        self.max_categories = 2\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"Initialize Z3 expressions from model and categoric features from data.\n",
    "        z3 expressions are built here for pkl compatibility (use fit after export pkl)\n",
    "        \"\"\"\n",
    "        set_option(rational_to_decimal=True)\n",
    "\n",
    "        self.categoric_features = self.get_categoric_features(self.data)\n",
    "        self.T_model = self.model_trees_expression(self.model)\n",
    "        self.T = self.T_model\n",
    "\n",
    "    def explain(self, instance, reorder=\"asc\"):\n",
    "        self.I = self.instance_expression(instance)\n",
    "        self.D = self.decision_function_expression(self.model, [instance])\n",
    "        return self.explain_expression(self.I, self.T, self.D, self.model, reorder)\n",
    "\n",
    "    def get_categoric_features(self, data: np.ndarray):\n",
    "        \"\"\"\n",
    "        Recebe um dataset e retorna uma fórmula no z3 com:\n",
    "        - Restrições de valor máximo e mínimo para features contínuas.\n",
    "        - Restrições de igualdade para features categóricas binárias.\n",
    "        \"\"\"\n",
    "        categoric_features = []\n",
    "        for i in range(data.shape[1]):\n",
    "            feature_values = data[:, i]\n",
    "            unique_values = np.unique(feature_values)\n",
    "            if len(unique_values) <= self.max_categories:\n",
    "                categoric_features.append(self.columns[i])\n",
    "\n",
    "        return categoric_features\n",
    "\n",
    "    def feature_constraints(self, constraints=[]):\n",
    "        \"\"\"TODO\n",
    "        esperado receber limites das features pelo usuário\n",
    "        formato previso: matriz/dataframe [feaature, min/max, valor]\n",
    "        constraaint_expression = \"constraaint_df_to_feature()\"\n",
    "        \"\"\"\n",
    "        return\n",
    "\n",
    "    def model_trees_expression(self, model):\n",
    "        \"\"\"\n",
    "        Constrói expressões lógicas para todas as árvores de decisão em um dataframe de XGBoost.\n",
    "        Para árvores que são apenas folhas, gera diretamente um And com o valor da folha.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): Dataframe contendo informações das árvores.\n",
    "            class_index (int): Índice da classe atual.\n",
    "\n",
    "        Returns:\n",
    "            z3.ExprRef: Fórmula representando todos os caminhos de todas as árvores.\n",
    "        \"\"\"\n",
    "        df = model.get_booster().trees_to_dataframe()\n",
    "        if model.get_booster().feature_names == None:\n",
    "            feature_map = {f\"f{i}\": col for i, col in enumerate(self.columns)}\n",
    "            df[\"Feature\"] = df[\"Feature\"].replace(feature_map)\n",
    "\n",
    "        df[\"Split\"] = df[\"Split\"].round(4)\n",
    "        self.booster_df = df\n",
    "        class_index = 0  # if model.n_classes_ == 2:\n",
    "        all_tree_formulas = []\n",
    "\n",
    "        for tree_index in df[\"Tree\"].unique():\n",
    "            tree_df = df[df[\"Tree\"] == tree_index]\n",
    "            o = Real(f\"o_{tree_index}_{class_index}\")\n",
    "\n",
    "            if len(tree_df) == 1 and tree_df.iloc[0][\"Feature\"] == \"Leaf\":\n",
    "                leaf_value = tree_df.iloc[0][\"Gain\"]\n",
    "                all_tree_formulas.append(And(o == leaf_value))\n",
    "                continue\n",
    "            path_formulas = []\n",
    "\n",
    "            def get_conditions(node_id):\n",
    "                conditions = []\n",
    "                current_node = tree_df[tree_df[\"ID\"] == node_id]\n",
    "                if current_node.empty:\n",
    "                    return conditions\n",
    "\n",
    "                parent_node = tree_df[\n",
    "                    (tree_df[\"Yes\"] == node_id) | (tree_df[\"No\"] == node_id)\n",
    "                ]\n",
    "                if not parent_node.empty:\n",
    "                    parent_data = parent_node.iloc[0]\n",
    "                    feature = parent_data[\"Feature\"]\n",
    "                    split_value = parent_data[\"Split\"]\n",
    "                    x = Real(feature)\n",
    "                    if parent_data[\"Yes\"] == node_id:\n",
    "                        conditions.append(x < split_value)\n",
    "                    else:\n",
    "                        conditions.append(x >= split_value)\n",
    "                    conditions = get_conditions(parent_data[\"ID\"]) + conditions\n",
    "\n",
    "                return conditions\n",
    "\n",
    "            for _, node in tree_df[tree_df[\"Feature\"] == \"Leaf\"].iterrows():\n",
    "                leaf_value = node[\"Gain\"]\n",
    "                leaf_id = node[\"ID\"]\n",
    "                conditions = get_conditions(leaf_id)\n",
    "                path_formula = And(*conditions)\n",
    "                implication = Implies(path_formula, o == leaf_value)\n",
    "                path_formulas.append(implication)\n",
    "\n",
    "            all_tree_formulas.append(And(*path_formulas))\n",
    "        return And(*all_tree_formulas)\n",
    "\n",
    "    def decision_function_expression(self, model, x):\n",
    "        n_classes = 1 if model.n_classes_ <= 2 else model.n_classes_\n",
    "        predicted_class = model.predict(x)[0]\n",
    "        n_estimators = len(model.get_booster().get_dump())\n",
    "\n",
    "        estimator_pred = Solver()\n",
    "        estimator_pred.add(self.I)\n",
    "        estimator_pred.add(self.T)\n",
    "        variables = [Real(f\"o_{i}_0\") for i in range(n_estimators)]\n",
    "        if estimator_pred.check() == sat:\n",
    "            solvermodel = estimator_pred.model()\n",
    "            total_sum = sum(\n",
    "                float(solvermodel.eval(var).as_fraction()) for var in variables\n",
    "            )\n",
    "        else:\n",
    "            total_sum = 0\n",
    "            print(\"estimator error\")\n",
    "        init_value = model.predict(x, output_margin=True)[0] - total_sum\n",
    "        # print(\"init:\", round(init_value, 2))\n",
    "\n",
    "        equation_list = []\n",
    "        for class_number in range(n_classes):\n",
    "            estimator_list = []\n",
    "            for estimator_number in range(\n",
    "                int(len(model.get_booster().get_dump()) / n_classes)\n",
    "            ):\n",
    "                o = Real(f\"o_{estimator_number}_{class_number}\")\n",
    "                estimator_list.append(o)\n",
    "            equation_o = Sum(estimator_list) + init_value\n",
    "            equation_list.append(equation_o)\n",
    "\n",
    "        if n_classes <= 2:\n",
    "            if predicted_class == 0:\n",
    "                final_equation = equation_list[0] < 0\n",
    "            else:\n",
    "                final_equation = equation_list[0] > 0\n",
    "        else:\n",
    "            compare_equation = []\n",
    "            for class_number in range(n_classes):\n",
    "                if predicted_class != class_number:\n",
    "                    compare_equation.append(\n",
    "                        equation_list[predicted_class] > equation_list[class_number]\n",
    "                    )\n",
    "            final_equation = And(compare_equation)\n",
    "\n",
    "        return final_equation\n",
    "\n",
    "    def instance_expression(self, instance):\n",
    "        formula = [Real(self.columns[i]) == value for i, value in enumerate(instance)]\n",
    "        return formula\n",
    "\n",
    "    def explain_expression(self, I, T, D, model, reorder):\n",
    "        i_expression = I.copy()\n",
    "        T_s = T\n",
    "        D_s = D\n",
    "\n",
    "        importances = model.feature_importances_\n",
    "        non_zero_indices = np.where(importances != 0)[0]\n",
    "\n",
    "        if reorder == \"asc\":\n",
    "            sorted_feature_indices = non_zero_indices[\n",
    "                np.argsort(importances[non_zero_indices])\n",
    "            ]\n",
    "            i_expression = [i_expression[i] for i in sorted_feature_indices]\n",
    "        elif reorder == \"desc\":\n",
    "            sorted_feature_indices = non_zero_indices[\n",
    "                np.argsort(-importances[non_zero_indices])\n",
    "            ]\n",
    "            i_expression = [i_expression[i] for i in sorted_feature_indices]\n",
    "\n",
    "        for feature in i_expression.copy():\n",
    "\n",
    "            i_expression.remove(feature)\n",
    "\n",
    "            # prove(Implies(And(And(i_expression), T), D))\n",
    "            if self.is_proved(Implies(And(And(i_expression), T_s), D_s)):\n",
    "                continue\n",
    "                # print('proved')\n",
    "            else:\n",
    "                # print('not proved')\n",
    "                i_expression.append(feature)\n",
    "        # print(self.is_proved(Implies(And(And(i_expression), T_s), D_s)))\n",
    "        return i_expression\n",
    "\n",
    "    def is_proved(self, f):\n",
    "        s = Solver()\n",
    "        s.add(Not(f))\n",
    "        if s.check() == unsat:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def delta_expression(self, expression):\n",
    "        # print(delta_expressions)\n",
    "        return  # delta_expressions\n",
    "\n",
    "    def get_deltas(self, exp):\n",
    "        if exp and isinstance(exp[0], str):\n",
    "            expz3 = []\n",
    "            for token in exp:\n",
    "                tokens = token.split(\" == \")\n",
    "                expz3.append(Real(tokens[0]) == (tokens[1]))\n",
    "            exp = expz3\n",
    "        for expression in exp:\n",
    "            if str(expression.arg(0)) in self.categoric_features:\n",
    "                self.caterogic_expressions.append(expression)\n",
    "                exp = list(filter(lambda expr: not expr.eq(expression), exp))\n",
    "            else:\n",
    "                self.cumulative_range_expresson.append(expression)\n",
    "\n",
    "        delta_list = []\n",
    "        for expression in exp:\n",
    "\n",
    "            self.cumulative_range_expresson = list(\n",
    "                filter(\n",
    "                    lambda expr: not expr.eq(expression),\n",
    "                    self.cumulative_range_expresson,\n",
    "                )\n",
    "            )\n",
    "            lower_min, upper_min = self.optmize_delta(expression)\n",
    "\n",
    "            if lower_min != None:\n",
    "                delta_value_lower = self.get_delta_value(str(lower_min.value()))\n",
    "                self.cumulative_range_expresson.append(\n",
    "                    expression.arg(0) >= expression.arg(1) - delta_value_lower\n",
    "                )\n",
    "            else:\n",
    "                # print(\"unsat == open range lower\")\n",
    "                delta_value_lower = None\n",
    "\n",
    "            if upper_min != None:\n",
    "                delta_value_upper = self.get_delta_value(str(upper_min.value()))\n",
    "                self.cumulative_range_expresson.append(\n",
    "                    expression.arg(0) <= expression.arg(1) + delta_value_upper\n",
    "                )\n",
    "            else:\n",
    "                # print(\"unsat == open range upper\")\n",
    "                delta_value_upper = None\n",
    "\n",
    "            # print(expression, delta_value_lower, delta_value_upper)\n",
    "            delta_list.append([expression, delta_value_lower, delta_value_upper])\n",
    "\n",
    "        self.delta_list = delta_list\n",
    "        return delta_list\n",
    "\n",
    "    def get_delta_value(self, value):\n",
    "        if \"+ epsilon\" in value:\n",
    "            delta_value = float(value.split(\" + \")[0])\n",
    "        elif \"epsilon\" == value:\n",
    "            delta_value = 0\n",
    "        elif \"0\" == value:\n",
    "            print(\"ERROR: delta == 0, explanation is incorrect\")\n",
    "            delta_value = 0\n",
    "        else:\n",
    "            delta_value = round(float(value) - 0.01, 2)\n",
    "\n",
    "        return delta_value\n",
    "\n",
    "    def optmize_delta(self, expression):\n",
    "        delta_upper = Real(\"delta_upper\")\n",
    "        delta_lower = Real(\"delta_lower\")\n",
    "\n",
    "        self.delta_features = []\n",
    "\n",
    "        delta_expressions = []\n",
    "        delta_expressions.append(expression.arg(0) >= expression.arg(1) - delta_lower)\n",
    "        delta_expressions.append(expression.arg(0) <= expression.arg(1) + delta_upper)\n",
    "\n",
    "        self.delta_expressions = delta_expressions\n",
    "\n",
    "        expression_list = []\n",
    "        expression_list.append(And(self.cumulative_range_expresson))\n",
    "        expression_list.append(And(self.caterogic_expressions))\n",
    "        expression_list.append(And(self.delta_expressions))\n",
    "        expression_list.append(self.T)\n",
    "        expression_list.append(Not(self.D))\n",
    "        expression_list.append(delta_upper >= 0)\n",
    "        expression_list.append(delta_lower >= 0)\n",
    "\n",
    "        opt_lower = Optimize()\n",
    "        opt_lower.add(And(expression_list))\n",
    "        opt_lower.add(delta_upper == 0)\n",
    "        lower_min = opt_lower.minimize(delta_lower)\n",
    "        if opt_lower.check() != sat:\n",
    "            # print(\"lower unsat\")\n",
    "            lower_min = None\n",
    "\n",
    "        opt_upper = Optimize()\n",
    "        opt_upper.add(And(expression_list))\n",
    "        opt_upper.add(delta_lower == 0)\n",
    "        upper_min = opt_upper.minimize(delta_upper)\n",
    "        if opt_upper.check() != sat:\n",
    "            # print(\"upper unsat\")\n",
    "            upper_min = None\n",
    "\n",
    "        return lower_min, upper_min\n",
    "\n",
    "    def explain_range(self, instance, reorder=\"asc\", dataset_bounds=True, exp=None):\n",
    "        self.cumulative_range_expresson = []\n",
    "        self.caterogic_expressions = []\n",
    "        self.range_metric = 0\n",
    "        if exp == None:\n",
    "            exp = self.explain(instance, reorder)\n",
    "        if exp != []:\n",
    "            delta_list = self.get_deltas(exp)\n",
    "            range_exp = []\n",
    "            for expression, delta_lower, delta_upper in delta_list:\n",
    "                expname = str(expression.arg(0))\n",
    "\n",
    "                expvalue = float(expression.arg(1).as_fraction())\n",
    "                lower = None\n",
    "                upper = None\n",
    "                if delta_lower is not None:\n",
    "                    lower = round(expvalue - delta_lower, 2)\n",
    "                if delta_upper is not None:\n",
    "                    upper = round(expvalue + delta_upper, 2)\n",
    "\n",
    "                if dataset_bounds == True:\n",
    "                    idx = list(self.columns).index(expname)\n",
    "                    min_idx = np.min(self.data[:, idx])\n",
    "                    max_idx = np.max(self.data[:, idx])\n",
    "                    if lower is not None and lower < min_idx:\n",
    "                        lower = min_idx\n",
    "                    if upper is not None and upper > max_idx:\n",
    "                        upper = max_idx\n",
    "\n",
    "                    # self.range_metric += (upper - lower)\n",
    "                if lower == upper:\n",
    "                    range_exp.append(f\"{expression.arg(0)} == {expression.arg(1)}\")\n",
    "                else:\n",
    "                    if lower is None:\n",
    "                        range_exp.append(f\"{expname} <= {upper}\")\n",
    "                    elif upper is None:\n",
    "                        range_exp.append(f\"{expname} >= {lower}\")\n",
    "                    else:\n",
    "                        range_exp.append(f\"{lower} <= {expname} <= {upper}\")\n",
    "\n",
    "            for expression in self.caterogic_expressions:\n",
    "                range_exp.append(f\"{expression.arg(0)} == {expression.arg(1)}\")\n",
    "\n",
    "            return range_exp\n",
    "        else:\n",
    "            return exp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = iris.target\n",
    "\n",
    "# y = np.where(y == 0, 0, 1)  # converte em binario\n",
    "y[y == 2] = 0\n",
    "# X = X.iloc[:, :2] # corta colunas do df\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=101\n",
    ")\n",
    "\n",
    "xgbc = XGBClassifier(n_estimators=100, max_depth=3, learning_rate=0.1)\n",
    "xgbc.fit(X_train, y_train)\n",
    "\n",
    "preds = xgbc.predict(X_test)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = XGBoostExplainer(xgbc, X)\n",
    "explainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[petal length (cm) == 1.4]\n",
      "['petal length (cm) <= 2.99']\n"
     ]
    }
   ],
   "source": [
    "sample = [5.5, 4.2, 1.4, 0.2]\n",
    "exp = explainer.explain(sample, reorder=\"asc\")\n",
    "print(exp)\n",
    "\n",
    "print(explainer.explain_range(sample, reorder=\"asc\", exp=exp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
